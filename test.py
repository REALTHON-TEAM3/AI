import sounddevice as sd
from scipy.io.wavfile import write
import os
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))  # ë¬´ë£Œ í‚¤ ê°€ëŠ¥

def record_audio():
    fs = 44100  
    duration = 4  # ë…¹ìŒ ê¸¸ì´(ì´ˆ)
    print("ğŸ™ ë…¹ìŒ ì‹œì‘...")
    audio = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='int16')
    sd.wait()
    write("input.wav", fs, audio)
    print("ğŸ¤ ë…¹ìŒ ì™„ë£Œ! -> input.wav ì €ì¥ë¨")

def speech_to_text():
    print("ğŸ“ Whisper STT ë³€í™˜ ì¤‘...")
    with open("input.wav", "rb") as f:
        transcript = client.audio.transcriptions.create(
            model="whisper-1",
            file=f
        )
    return transcript.text

def generate_response(text):
    print("ğŸ¤– LLM ì‘ë‹µ ìƒì„± ì¤‘...")
    response = client.responses.create(
        model="gpt-4o-mini",  # ë¬´ë£Œë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ëŸ‰ LLM
        input=text
    )
    return response.output_text

if __name__ == "__main__":
    record_audio()

    text = speech_to_text()
    print("ğŸ“ ì¸ì‹ëœ ë¬¸ì¥:", text)

    response = generate_response(text)
    print("ğŸ¤– ëª¨ë¸ ì‘ë‹µ:", response)
